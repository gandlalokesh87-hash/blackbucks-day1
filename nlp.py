import nltk

from nltk.tokenize import word_tokenize

sentence="This is first class"

tokens =word_tokenize(sentence)

print (tokens)
